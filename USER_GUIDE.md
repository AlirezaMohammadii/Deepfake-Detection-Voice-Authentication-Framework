# Physics-Based Deepfake Detection System - User Guide\n\n**Version:** 3.1.0  \n**Last Updated:** June 2025  \n**Practical Usage Guide for the VoiceRadar System**\n\n> **Note**: For a complete overview, see [README.md](README.md). This guide focuses on practical usage scenarios and detailed troubleshooting.\n\n---\n\n## 📋 Table of Contents\n\n1. [Installation & Setup](#installation--setup)\n2. [Data Preparation](#data-preparation)\n3. [Processing Modes Guide](#processing-modes-guide)\n4. [Understanding Results](#understanding-results)\n5. [Advanced Usage](#advanced-usage)\n6. [Troubleshooting](#troubleshooting)\n7. [Performance Optimization](#performance-optimization)\n8. [Best Practices](#best-practices)\n\n---\n\n## 🛠️ Installation & Setup\n\n### Quick Installation\n```bash\n# Clone and setup\ngit clone <repository-url>\ncd physics_feature_test_project\npython -m venv venv\n\n# Activate environment\nvenv\\Scripts\\activate  # Windows\nsource venv/bin/activate  # macOS/Linux\n\n# Install dependencies\npip install -r requirements.txt\n```\n\n### Verification\n```bash\n# Test installation\npython -c \"import torch; print(f'PyTorch: {torch.__version__}')\"\npython -c \"import transformers; print('HuggingFace: OK')\"\n\n# Check GPU support (optional)\npython -c \"import torch; print(f'CUDA: {torch.cuda.is_available()}')\"\n```\n\n---\n\n## 📂 Data Preparation\n\n### Directory Structure\n```\ndata/\n├── user_01/\n│   ├── user01_genuine_001.wav\n│   ├── user01_deepfake_tts_001.wav\n│   └── user01_genuine_002.flac\n├── user_02/\n│   ├── user02_genuine_001.mp3\n│   └── user02_deepfake_tts_001.m4a\n└── ...\n```\n\n### File Requirements\n- **Formats**: WAV, MP3, FLAC, M4A\n- **Duration**: 1 second minimum, no maximum\n- **Size**: 200MB maximum per file\n- **Sample Rate**: Any (normalized to 16kHz automatically)\n\n### Naming Conventions\nInclude descriptive keywords for better analysis:\n- `genuine_*` or `real_*` for authentic audio\n- `deepfake_tts_*` for text-to-speech deepfakes\n- `deepfake_vc_*` for voice conversion deepfakes\n- `synthetic_*` for any AI-generated audio\n\n### Data Validation\n```bash\n# Count files\npython -c \"\nimport os\ndata_dir = 'data'\ntotal = sum([len(files) for r, d, files in os.walk(data_dir)])\nprint(f'Total audio files: {total}')\n\"\n```\n\n---\n\n## 🎛️ Processing Modes Guide\n\n### Mode Selection Strategy\n\n| Dataset Size | Recommended Mode | Reason |\n|--------------|------------------|--------|\n| < 50 files | Any mode | All modes handle small datasets efficiently |\n| 50-200 files | **Mode 1** (Enhanced) | Best balance of features and performance |\n| > 200 files | **Mode 1** or **Mode 3** | Enhanced processing or comprehensive analysis |\n| Quick testing | **Mode 2** (Lightweight) | Fastest processing |\n| Research | **Mode 3** (Bayesian) | Most comprehensive analysis |\n\n### Detailed Mode Comparison\n\n#### Mode 1: Enhanced Pipeline ⭐ **Recommended**\n```bash\necho \"1\" | python test_runner.py\n```\n- **Performance**: ~2.0s per file\n- **Memory**: 4-6GB\n- **Features**: Comprehensive validation, error recovery, batch optimization\n- **Best for**: General use, production environments\n- **Output**: Complete feature set with robust error handling\n\n#### Mode 2: Lightweight Pipeline\n```bash\necho \"2\" | python test_runner.py\n```\n- **Performance**: ~0.97s per file\n- **Memory**: 2-3GB\n- **Features**: Essential features only, optimized for speed\n- **Best for**: Quick testing, resource-constrained environments\n- **Output**: Core physics features with minimal overhead\n\n#### Mode 3: Bayesian-Enhanced Pipeline\n```bash\necho \"3\" | python test_runner.py\n```\n- **Performance**: ~1.09s per file\n- **Memory**: 4-8GB\n- **Features**: Probabilistic analysis, uncertainty quantification, causal analysis\n- **Best for**: Research, comprehensive analysis, uncertainty assessment\n- **Output**: Full feature set plus Bayesian analysis and confidence metrics\n\n---\n\n## 📊 Understanding Results\n\n### Primary Output Files\n\n#### 1. CSV Results (`results/physics_features_summary.csv`)\n**Key Columns:**\n- `physics_delta_fr_revised`: **Primary discriminator** (higher in deepfakes)\n- `physics_delta_ft_revised`: Translational dynamics\n- `physics_delta_fv_revised`: Vibrational dynamics\n- `physics_delta_f_total_revised`: Combined dynamics\n- `file_type`: genuine, deepfake_tts, etc.\n- `status`: success, failed\n\n#### 2. Interactive Dashboard (`visualizations/interactive/comprehensive_dashboard.html`)\n- **Physics Feature Distributions**: Compare genuine vs. deepfake patterns\n- **Statistical Analysis**: Significance tests and effect sizes\n- **Performance Metrics**: Processing times and success rates\n- **Correlation Analysis**: Feature relationships and dependencies\n\n#### 3. Static Plots (`visualizations/static/`)\n- `enhanced_physics_distributions.png`: Feature distribution comparisons\n- `enhanced_physics_correlation_analysis.png`: Feature correlation matrix\n- `comprehensive_statistical_comparison.png`: Statistical test results\n- `enhanced_performance_analysis.png`: Processing performance metrics\n\n### Interpreting Physics Features\n\n**Rotational Dynamics (Δf_r)** - **Most Important**\n- **Higher values** typically indicate deepfakes\n- **Statistical significance**: p < 0.05 in most datasets\n- **Interpretation**: Artificial speech shows more rotation in embedding space\n\n**Translational Dynamics (Δf_t)**\n- **Lower discrimination power** but still useful\n- **Interpretation**: Overall drift patterns in embedding space\n\n**Vibrational Dynamics (Δf_v)**\n- **High variability** across samples\n- **Interpretation**: High-frequency oscillations in embeddings\n\n**Total Dynamics (Δf_total)**\n- **Good composite measure** combining all dynamics\n- **Useful for overall authenticity assessment**\n\n---\n\n## 🔧 Advanced Usage\n\n### Resuming Interrupted Processing\n```bash\npython test_runner.py\n# When prompted: \"Resume from checkpoint? (y/n): y\"\n```\n\n### Custom Processing Parameters\nEdit configuration files in `config/` directory for advanced customization.\n\n### Batch Processing Tips\n- **Large datasets**: Use Mode 1 or Mode 3\n- **Memory constraints**: Use Mode 2 or reduce concurrency\n- **Time constraints**: Use Mode 2 for fastest processing\n\n### Project Management\n```bash\npython project_manager.py\n\n# Options:\n# 1. Analyze project state\n# 2. Safe cleanup (remove cache/temp files)\n# 3. Complete reset (fresh start)\n# 4. Exit\n```\n\n---\n\n## 🚨 Troubleshooting\n\n### Common Issues & Solutions\n\n#### Import Errors\n```bash\n# Verify PyTorch installation\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n\n# Verify transformers\npip install transformers\n\n# Test imports\npython -c \"import torch, transformers; print('All imports OK')\"\n```\n\n#### Model Download Issues\n```bash\n# Clear cache and retry\npython project_manager.py  # Choose option 2\npython test_runner.py\n\n# Manual cache clear\nrm -rf cache/*  # Linux/macOS\ndel cache\\*.* /q  # Windows\n```\n\n#### Memory Issues\n```bash\n# Use lightweight mode\necho \"2\" | python test_runner.py\n\n# Reduce concurrency (edit test_runner.py)\n# Change: concurrency_limit = 1\n```\n\n#### Processing Failures\n1. **Check error logs**: `results/error_log.txt`\n2. **Review system logs**: `logs/` directory\n3. **Validate input files**: Ensure proper format and size\n4. **Check disk space**: Ensure sufficient storage\n5. **Verify permissions**: Ensure write access to output directories\n\n#### GPU Issues\n```bash\n# Force CPU mode if GPU causes issues\nexport CUDA_VISIBLE_DEVICES=\"\"  # Linux/macOS\nset CUDA_VISIBLE_DEVICES=  # Windows\npython test_runner.py\n```\n\n### Error Code Reference\n\n| Error Type | Likely Cause | Solution |\n|------------|--------------|----------|\n| Import Error | Missing dependencies | Reinstall requirements |\n| CUDA Error | GPU memory/driver issue | Use CPU mode |\n| File Not Found | Missing audio files | Check data directory |\n| Permission Error | Write access denied | Check folder permissions |\n| Memory Error | Insufficient RAM | Use lightweight mode |\n\n---\n\n## ⚡ Performance Optimization\n\n### Hardware Optimization\n\n**CPU Optimization**\n```python\n# In test_runner.py, adjust concurrency:\nconcurrency_limit = min(4, os.cpu_count())  # Adjust based on your CPU\n```\n\n**Memory Optimization**\n- **Large datasets**: Use Mode 1 with batch processing\n- **Limited RAM**: Use Mode 2 (Lightweight)\n- **Monitor usage**: Check Task Manager/Activity Monitor\n\n**Storage Optimization**\n- **Use SSD**: Significantly faster cache and model loading\n- **Cache location**: Ensure cache directory is on fastest drive\n- **Cleanup regularly**: Use project manager for maintenance\n\n### Dataset Size Guidelines\n\n| Files | Mode | Expected Time | Memory |\n|-------|------|---------------|--------|\n| 10-50 | Any | 1-5 minutes | 2-6GB |\n| 50-100 | Mode 1 | 5-10 minutes | 4-6GB |\n| 100-200 | Mode 1 | 10-20 minutes | 4-8GB |\n| 200+ | Mode 1/3 | 20+ minutes | 6-8GB |\n\n---\n\n## 💡 Best Practices\n\n### Data Organization\n1. **Consistent naming**: Use clear, descriptive filenames\n2. **Balanced datasets**: Include both genuine and deepfake samples\n3. **Quality control**: Ensure audio quality and proper labeling\n4. **Backup important data**: Keep copies of original datasets\n\n### Processing Workflow\n1. **Start small**: Test with a few files first\n2. **Use appropriate mode**: Match mode to your use case\n3. **Monitor progress**: Check logs for any issues\n4. **Validate results**: Review output files and visualizations\n\n### Maintenance\n1. **Regular cleanup**: Use project manager monthly\n2. **Update dependencies**: Keep packages current\n3. **Monitor disk space**: Cache can grow large\n4. **Backup results**: Save important analysis results\n\n### Research Usage\n1. **Document parameters**: Keep track of processing settings\n2. **Version control**: Use git for experiment tracking\n3. **Statistical validation**: Ensure sufficient sample sizes\n4. **Reproducibility**: Save exact configurations and data\n\n---\n\n## 📞 Getting Help\n\n### Self-Diagnosis\n1. **Check README.md**: Comprehensive overview and quick start\n2. **Review error logs**: `results/error_log.txt` and `logs/`\n3. **Run project analysis**: `python project_manager.py` → Option 1\n4. **Verify installation**: Test imports and dependencies\n\n### Reporting Issues\nWhen reporting problems, include:\n- **System info**: OS, Python version, hardware specs\n- **Error messages**: Complete error logs\n- **Data characteristics**: File count, formats, sizes\n- **Processing mode**: Which mode was used\n- **Steps to reproduce**: Exact commands and sequence\n\n---\n\n**🎯 Ready to start? Run `python test_runner.py` and choose your processing mode!**" 