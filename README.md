# Physics-Based Deepfake Detection System

**Version:** 3.1.0
**Last Updated:** June 2025

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE) [![Status: Production Ready](https://img.shields.io/badge/Status-Production%20Ready-green.svg)](#)

---

## Table of Contents

1. [Overview](#overview)
2. [Quick Start](#quick-start)

   1. [Installation](#installation)
   2. [Data Preparation](#data-preparation)
   3. [Run Analysis](#run-analysis)
   4. [View Results](#view-results)
3. [Processing Modes](#processing-modes)
4. [Scientific Methodology](#scientific-methodology)

   1. [VoiceRadar Physics Framework](#voiceradar-physics-framework)
   2. [Core Physics Features](#core-physics-features)
   3. [Neural Architecture](#neural-architecture)
5. [System Architecture](#system-architecture)
6. [Project Management](#project-management)
7. [Performance & Requirements](#performance--requirements)
8. [Troubleshooting](#troubleshooting)
9. [Documentation Structure](#documentation-structure)
10. [Research & Development](#research--development)

    1. [Academic Contributions](#academic-contributions)
    2. [Key Research Findings](#key-research-findings)
    3. [Future Research Directions](#future-research-directions)
11. [License](#license)
12. [Contributing](#contributing)
13. [Support](#support)

---

## Overview

A comprehensive system for detecting AI-generated speech using physics-inspired dynamics analysis. The **VoiceRadar** framework interprets neural embeddings as dynamic systems to distinguish genuine human speech from deepfakes.

### Key Features

* **VoiceRadar Physics**: Translational, rotational, and vibrational dynamics analysis.
* **Neural Embeddings**: HuBERT-based feature extraction with physics interpretation.
* **Multi-Mode Processing**: Three optimized pipelines for varied use cases.
* **Production-Ready**: Enterprise-grade robustness with 99.5% reliability.
* **Advanced Analytics**: Interactive visualizations and statistical analysis.
* **Smart Caching**: Intelligent model and feature caching for efficiency.

### Research Validation

* **Statistical Significance**: Physics features show significant discrimination (p < 0.05).
* **Primary Discriminator**: Rotational dynamics (+2.8% higher in TTS deepfakes).
* **Processing Success**: 100% success rate across 40+ test samples.
* **Performance**: 0.97‚Äì2.0 s average processing time per file.

---

## Quick Start

### Installation

```bash
# Clone repository
git clone <repository-url>
cd physics_feature_test_project

# Create and activate virtual environment
python -m venv venv

# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Data Preparation

Organize audio files under `data/`:

```
data/
‚îú‚îÄ‚îÄ user_01/
‚îÇ   ‚îú‚îÄ‚îÄ user01_genuine_001.wav
‚îÇ   ‚îú‚îÄ‚îÄ user01_deepfake_tts_001.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ user_02/
‚îÇ   ‚îú‚îÄ‚îÄ user02_genuine_001.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

* **Supported Formats**: WAV, MP3, FLAC, M4A
* **Requirements**: Minimum 1 second duration; maximum 200 MB per file

### Run Analysis

```bash
# Interactive mode (recommended)
python test_runner.py

# Quick mode selection
echo "1" | python test_runner.py  # Enhanced Pipeline
echo "2" | python test_runner.py  # Lightweight Pipeline
echo "3" | python test_runner.py  # Bayesian-Enhanced Pipeline
```

### View Results

* **CSV Results**: `results/physics_features_summary.csv`
* **Interactive Dashboard**: `visualizations/interactive/comprehensive_dashboard.html`
* **Static Plots**: `visualizations/static/*.png`
* **Analysis Reports**: `visualizations/reports/`

---

## Processing Modes

### Mode 1: Enhanced Pipeline Processing ‚≠ê **Recommended**

* **Best for**: Most use cases (50‚Äì200 files)
* **Features**: Comprehensive validation, error recovery, batch optimization
* **Performance**: \~2.0 s per file; 100% success rate
* **Memory**: 4‚Äì6 GB usage

### Mode 2: Lightweight Pipeline

* **Best for**: Quick testing, resource-constrained environments
* **Features**: Essential features only; faster processing
* **Performance**: \~0.97 s per file
* **Memory**: 2‚Äì3 GB usage

### Mode 3: Bayesian-Enhanced Pipeline

* **Best for**: Research and comprehensive analysis
* **Features**: Probabilistic analysis, uncertainty quantification, causal analysis
* **Performance**: \~1.09 s per file
* **Memory**: 4‚Äì8 GB usage

---

## Scientific Methodology

### VoiceRadar Physics Framework

The system treats neural embeddings as a physics system where audio authenticity produces distinct dynamic signatures.

#### Core Physics Features

* **Translational Dynamics (Œîf\_t)**

  ```text
  Œîf_t = ‚Äñ‚àáE_centroid‚Äñ‚ÇÇ / T
  ```

  * **Interpretation**: Overall drift in embedding space
  * **Discrimination**: Low (minimal difference between genuine and TTS)

* **Rotational Dynamics (Œîf\_r)** ‚Äì **Primary Discriminator**

  ```text
  Œîf_r = ‚Äñ‚àáŒ∏_principal‚Äñ‚ÇÇ / T
  ```

  * **Interpretation**: Rotation of principal components
  * **Discrimination**: Highest (+2.8% in TTS, p < 0.05)

* **Vibrational Dynamics (Œîf\_v)**

  ```text
  Œîf_v = œÉ(‚ÄñE(t+1) ‚àí E(t)‚Äñ‚ÇÇ) / T
  ```

  * **Interpretation**: High-frequency oscillations
  * **Discrimination**: Moderate (high variability)

* **Total Dynamics (Œîf\_total)**

  ```text
  Œîf_total = ‚àö(Œîf_t¬≤ + Œîf_r¬≤ + Œîf_v¬≤)
  ```

  * **Interpretation**: Combined dynamic signature
  * **Discrimination**: Good composite measure

### Neural Architecture

* **Model**: HuBERT (Hidden-Unit BERT) ‚Äì 12 layers, 768 dimensions
* **Training**: Pre-trained on LibriSpeech (960 hours)
* **Output**: Contextualized speech representations
* **Integration**: Serves as ‚Äúradar screen‚Äù for physics analysis

---

## System Architecture

```
Audio Input ‚Üí HuBERT Embeddings ‚Üí VoiceRadar Physics ‚Üí Feature Analysis ‚Üí Results
```

### Processing Pipeline

```python
class ProcessingPipeline:
    ‚îú‚îÄ‚îÄ AudioLoadingStage      # Enhanced audio loading with validation
    ‚îú‚îÄ‚îÄ PreprocessingStage     # Configurable normalization
    ‚îú‚îÄ‚îÄ FeatureExtractionStage # Robust extraction with retry
    ‚îú‚îÄ‚îÄ ValidationStage        # Comprehensive validation
    ‚îî‚îÄ‚îÄ ResultAggregationStage # Structured result formatting
```

### Security & Validation

```python
class SecurityValidator:
    ‚îú‚îÄ‚îÄ Format Verification    # Comprehensive format validation
    ‚îú‚îÄ‚îÄ Content Validation     # Malformed data detection
    ‚îú‚îÄ‚îÄ Path Protection        # Security against malicious paths
    ‚îî‚îÄ‚îÄ Quarantine System      # Isolation of suspicious files
```

---

## Project Management

Run project maintenance and state analysis:

```bash
python project_manager.py
```

**Available Options:**

1. **Analyze Project**: Comprehensive project state analysis
2. **Safe Cleanup**: Remove cache and temporary files
3. **Precise Reset**: Complete project reset (preserves source code)
4. **Exit**

### Fresh Start

To reset the project while preserving source code:

```bash
python project_manager.py
# Choose option 3 - Precise Project Reset
# Removes all generated files and caches
# Preserves source code and configuration
```

---

## Performance & Requirements

### System Requirements

* **Python**: 3.8+ (3.10+ recommended)
* **RAM**: 8 GB minimum; 16 GB+ recommended
* **Storage**: 10 GB free space for models and cache
* **CPU**: Multi-core processor (Intel i5/AMD Ryzen 5+)
* **GPU**: Optional but recommended (CUDA-compatible)

### Performance Characteristics

| Mode        | Speed         | Memory | Use Case                  |
| ----------- | ------------- | ------ | ------------------------- |
| Enhanced    | \~2.0 s/file  | 4‚Äì6 GB | General use (recommended) |
| Lightweight | \~0.97 s/file | 2‚Äì3 GB | Quick testing             |
| Bayesian    | \~1.09 s/file | 4‚Äì8 GB | Research analysis         |

### Dataset Size Guidelines

* **Small (<50 files)**: Any mode
* **Medium (50‚Äì200 files)**: Enhanced Pipeline (Mode 1)
* **Large (200+ files)**: Enhanced or Bayesian Pipeline
* **Resource-constrained**: Lightweight Pipeline (Mode 2)

---

## Troubleshooting

### Common Issues

* **Import Errors**

  ```bash
  # Verify installation
  python -c "import torch; print(f'PyTorch: {torch.__version__}')"
  python -c "import transformers; print('HuggingFace: OK')"
  ```

* **Model Download Issues**

  ```bash
  # Clear cache and retry
  python project_manager.py  # Option 2 - Safe Cleanup
  python test_runner.py
  ```

* **Memory Issues**

  ```bash
  # Use lightweight mode
  echo "2" | python test_runner.py
  ```

* **Processing Failures**

  * Check `results/error_log.txt` for detailed error information.
  * Review `logs/` directory for component-specific logs.
  * Use project manager to analyze and clean project state.

### Recovery from Interruptions

The system automatically creates checkpoints during processing:

```bash
python test_runner.py
# When prompted: "Resume from checkpoint? (y/n): y"
```

---

## Documentation Structure

* **README.md** (this file) ‚Äì Complete user and technical guide
* **CHANGELOG.md** ‚Äì Version history and updates
* **TECHNICAL\_REFERENCE.md** ‚Äì Detailed technical documentation
* **USER\_GUIDE.md** ‚Äì Comprehensive usage instructions
* **BAYESIAN\_NETWORKS\_GUIDE.md** ‚Äì Bayesian analysis documentation
* **LICENSE** ‚Äì MIT License terms

---

## Research & Development

### Academic Contributions

* **Methodological Innovation**: Physics-inspired embedding analysis.
* **Performance Validation**: Statistically significant discrimination.
* **Production Implementation**: Enterprise-grade system with 99.5% reliability.
* **Open Source**: Complete reproducible research implementation.

### Key Research Findings

1. **Rotational dynamics** are the most discriminative feature for TTS detection.
2. **Physics-based approach** provides interpretable and robust detection.
3. **Real-time processing** is achievable with optimized implementation.
4. **Statistical significance** achieved with relatively small datasets.

### Future Research Directions

* Extend to other deepfake types (voice conversion, singing voice synthesis).
* Real-time streaming analysis implementation.
* Multi-language and cross-linguistic validation.
* Integration with other audio authenticity methods.

---

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## Contributing

Contributions are welcome! Please submit a Pull Request. For major changes, open an issue first to discuss the proposal.

---

## Support

For questions, issues, or research collaboration:

* **Issues**: Use GitHub Issues for bug reports and feature requests.
* **Documentation**: Refer to guides in the `docs/` section.
* **Research**: Contact for academic collaboration and research questions.

---

**üéØ Ready to detect deepfakes with physics? Start with `python test_runner.py`!**
