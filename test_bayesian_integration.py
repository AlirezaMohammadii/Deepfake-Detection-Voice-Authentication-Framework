#!/usr/bin/env python3
"""
Comprehensive Test Script for Bayesian Networks Integration
Demonstrates the complete physics-based deepfake detection system with Bayesian analysis
"""

import asyncio
import torch
import torchaudio
import numpy as np
import time
from pathlib import Path
import logging
import sys
import os
from typing import Dict, Any, List

# Setup path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'src'))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import our modules with correct paths
try:
    from core.feature_extractor import ComprehensiveFeatureExtractor
    from bayesian.core.bayesian_engine import BayesianDeepfakeEngine, BayesianConfig
    from bayesian.utils.user_context import UserContextManager
    from utils.config_loader import settings
    logger.info("âœ“ Successfully imported all required modules")
except ImportError as e:
    logger.error(f"âŒ Import error: {e}")
    sys.exit(1)

class BayesianIntegrationDemo:
    """Comprehensive demonstration of Bayesian Networks integration"""
    
    def __init__(self, config_profile: str = "default"):
        self.config_profile = config_profile
        self.feature_extractor = None
        self.user_manager = None
        self.test_results = []
        
    async def initialize_system(self):
        """Initialize the complete system with Bayesian integration"""
        logger.info("ğŸ”§ Initializing Bayesian Networks Deepfake Detection System...")
        
        try:
            # Initialize feature extractor
            self.feature_extractor = ComprehensiveFeatureExtractor()
            
            # Check if Bayesian integration is available
            if hasattr(self.feature_extractor, 'bayesian_engine') and self.feature_extractor.bayesian_engine:
                logger.info("âœ… Bayesian Networks integration is enabled")
                
                # Initialize user context manager
                self.user_manager = UserContextManager()
                
                logger.info(f"ğŸ“Š Using configuration profile: {self.config_profile}")
                logger.info(f"ğŸ§  Bayesian Engine: {type(self.feature_extractor.bayesian_engine).__name__}")
                
            else:
                logger.warning("âš ï¸ Bayesian Networks not available - running in basic mode")
            
            logger.info("âœ¨ System initialization complete!")
            
        except Exception as e:
            logger.error(f"âŒ System initialization failed: {e}")
            raise
    
    async def test_synthetic_audio_analysis(self):
        """Test Bayesian analysis with synthetic audio samples"""
        logger.info("\nğŸµ Testing Synthetic Audio Analysis...")
        
        # Create synthetic audio samples representing different scenarios
        test_scenarios = [
            {
                'name': 'Genuine Human Speech (Low Dynamics)',
                'delta_fr': 6.0,  # Low rotational dynamics
                'delta_ft': 0.05,  # Low translational dynamics  
                'delta_fv': 0.8,   # Low vibrational dynamics
                'expected_authenticity': 'high'
            },
            {
                'name': 'TTS Generated Speech (High Dynamics)',
                'delta_fr': 8.5,   # High rotational dynamics (TTS artifact)
                'delta_ft': 0.12,  # High translational dynamics
                'delta_fv': 2.0,   # High vibrational dynamics
                'expected_authenticity': 'low'
            },
            {
                'name': 'Borderline Case (Medium Dynamics)',
                'delta_fr': 7.0,   # Medium rotational dynamics
                'delta_ft': 0.07,  # Medium translational dynamics
                'delta_fv': 1.2,   # Medium vibrational dynamics
                'expected_authenticity': 'uncertain'
            },
            {
                'name': 'High-Quality TTS (Sophisticated)',
                'delta_fr': 7.8,   # High-ish rotational dynamics
                'delta_ft': 0.09,  # Medium-high translational
                'delta_fv': 1.6,   # High vibrational
                'expected_authenticity': 'low'
            }
        ]
        
        user_id = "test_user_001"
        
        # Initialize user context if available
        if self.user_manager:
            logger.info(f"ğŸ‘¤ Created test user context: {user_id}")
        
        for i, scenario in enumerate(test_scenarios):
            logger.info(f"\nğŸ“‹ Scenario {i+1}: {scenario['name']}")
            
            # Create synthetic audio with controlled characteristics
            synthetic_audio = self._create_synthetic_audio_with_physics_features(
                scenario['delta_fr'], scenario['delta_ft'], scenario['delta_fv']
            )
            
            # Analyze with full pipeline
            results = await self._analyze_audio_sample(
                synthetic_audio, 22050, user_id, scenario['name']
            )
            
            # Store results
            self.test_results.append({
                'scenario': scenario,
                'results': results,
                'timestamp': time.time()
            })
            
            # Log analysis results
            self._log_analysis_results(scenario, results)
            
            # Small delay between samples for temporal analysis
            await asyncio.sleep(0.5)
        
        logger.info(f"ğŸ“Š Analysis completed for user {user_id}")
    
    async def test_temporal_consistency_analysis(self):
        """Test temporal consistency analysis with sequence of samples"""
        logger.info("\nâ±ï¸ Testing Temporal Consistency Analysis...")
        
        user_id = "temporal_test_user"
        
        if self.user_manager:
            logger.info(f"ğŸ‘¤ Testing with user: {user_id}")
        
        # Simulate sequence of audio samples from same user
        # Scenario: Genuine user with consistent characteristics
        genuine_sequence = [
            {'delta_fr': 6.0, 'delta_ft': 0.05, 'delta_fv': 0.9},
            {'delta_fr': 6.2, 'delta_ft': 0.06, 'delta_fv': 0.85},
            {'delta_fr': 5.9, 'delta_ft': 0.048, 'delta_fv': 0.92},
            {'delta_fr': 6.1, 'delta_ft': 0.052, 'delta_fv': 0.88},
            {'delta_fr': 6.3, 'delta_ft': 0.058, 'delta_fv': 0.95}
        ]
        
        logger.info("ğŸ¯ Analyzing sequence of genuine speech samples...")
        temporal_results = []
        
        for i, features in enumerate(genuine_sequence):
            logger.info(f"   Sample {i+1}/5: Processing...")
            
            synthetic_audio = self._create_synthetic_audio_with_physics_features(
                features['delta_fr'], features['delta_ft'], features['delta_fv']
            )
            
            results = await self._analyze_audio_sample(
                synthetic_audio, 22050, user_id, f"temporal_sample_{i+1}"
            )
            
            temporal_results.append(results)
            
            # Log temporal consistency if available
            if 'bayesian_analysis' in results and results['bayesian_analysis']:
                ba = results['bayesian_analysis']
                logger.info(f"      Spoof Prob: {ba.spoof_probability:.3f}, "
                          f"Confidence: {ba.confidence_score:.3f}, "
                          f"Temporal Consistency: {ba.temporal_consistency}")
            
            await asyncio.sleep(0.3)
        
        # Now test with inconsistent sequence (potential attack)
        logger.info("\nğŸš¨ Testing inconsistent sequence (potential attack)...")
        
        attack_sequence = [
            {'delta_fr': 6.0, 'delta_ft': 0.05, 'delta_fv': 0.9},   # Start genuine
            {'delta_fr': 8.5, 'delta_ft': 0.12, 'delta_fv': 2.1},  # Sudden TTS
            {'delta_fr': 7.8, 'delta_ft': 0.10, 'delta_fv': 1.8},  # More TTS
            {'delta_fr': 6.1, 'delta_ft': 0.06, 'delta_fv': 0.95}, # Back to genuine?
        ]
        
        for i, features in enumerate(attack_sequence):
            logger.info(f"   Attack Sample {i+1}/4: Processing...")
            
            synthetic_audio = self._create_synthetic_audio_with_physics_features(
                features['delta_fr'], features['delta_ft'], features['delta_fv']
            )
            
            results = await self._analyze_audio_sample(
                synthetic_audio, 22050, user_id, f"attack_sample_{i+1}"
            )
            
            if 'bayesian_analysis' in results and results['bayesian_analysis']:
                ba = results['bayesian_analysis']
                logger.info(f"      Spoof Prob: {ba.spoof_probability:.3f}, "
                          f"Confidence: {ba.confidence_score:.3f}, "
                          f"Temporal Consistency: {ba.temporal_consistency}")
            
            await asyncio.sleep(0.3)
    
    async def test_user_adaptation(self):
        """Test user adaptation and personalization"""
        logger.info("\nğŸ‘¤ Testing User Adaptation and Personalization...")
        
        if not self.user_manager:
            logger.info("ğŸ”§ Running basic adaptation test without user management")
        
        # Create two different user profiles
        users = [
            {
                'id': 'user_deep_voice',
                'characteristics': {'delta_fr': 5.5, 'delta_ft': 0.04, 'delta_fv': 0.7},
                'description': 'User with naturally low dynamics (deep voice)'
            },
            {
                'id': 'user_high_voice', 
                'characteristics': {'delta_fr': 6.8, 'delta_ft': 0.08, 'delta_fv': 1.1},
                'description': 'User with naturally higher dynamics (higher voice)'
            }
        ]
        
        for user in users:
            logger.info(f"\nğŸ”„ Testing adaptation for: {user['description']}")
            
            user_id = user['id']
            
            # Provide several genuine samples to establish baseline
            logger.info("   Establishing user baseline with genuine samples...")
            for i in range(3):  # Reduced from 5 for simpler test
                # Add slight variation around user's natural characteristics
                variation_fr = user['characteristics']['delta_fr'] + np.random.normal(0, 0.1)
                variation_ft = user['characteristics']['delta_ft'] + np.random.normal(0, 0.005)
                variation_fv = user['characteristics']['delta_fv'] + np.random.normal(0, 0.05)
                
                synthetic_audio = self._create_synthetic_audio_with_physics_features(
                    variation_fr, variation_ft, variation_fv
                )
                
                results = await self._analyze_audio_sample(
                    synthetic_audio, 22050, user_id, f"baseline_sample_{i+1}"
                )
                
                # Log results without complex user profile updates
                if 'bayesian_analysis' in results and results['bayesian_analysis']:
                    ba = results['bayesian_analysis']
                    logger.info(f"      Baseline {i+1}: Spoof Prob: {ba.spoof_probability:.3f}, "
                              f"Confidence: {ba.confidence_score:.3f}")
            
            # Now test with TTS sample - should be detected despite user's natural higher dynamics
            logger.info("   Testing TTS detection for this user profile...")
            tts_features = {
                'delta_fr': user['characteristics']['delta_fr'] + 1.5,  # Add TTS signature
                'delta_ft': user['characteristics']['delta_ft'] + 0.05,
                'delta_fv': user['characteristics']['delta_fv'] + 0.8
            }
            
            synthetic_tts = self._create_synthetic_audio_with_physics_features(
                tts_features['delta_fr'], tts_features['delta_ft'], tts_features['delta_fv']
            )
            
            tts_results = await self._analyze_audio_sample(
                synthetic_tts, 22050, user_id, "tts_test"
            )
            
            if 'bayesian_analysis' in tts_results and tts_results['bayesian_analysis']:
                ba = tts_results['bayesian_analysis']
                logger.info(f"      TTS Test: Spoof Prob: {ba.spoof_probability:.3f} "
                          f"(should be high), Confidence: {ba.confidence_score:.3f}")
            
            logger.info(f"   âœ… User adaptation test completed for {user_id}")
    
    async def _analyze_audio_sample(self, audio: torch.Tensor, sr: int, 
                                  user_id: str, sample_name: str) -> Dict[str, Any]:
        """Analyze a single audio sample with full pipeline"""
        try:
            # Extract features with Bayesian analysis
            results = await self.feature_extractor.extract_features(
                waveform=audio,
                sr=sr,
                processing_mode=f"bayesian_demo_{user_id}"
            )
            
            # Update user context if available
            if self.user_manager and 'bayesian_analysis' in results and results['bayesian_analysis']:
                authenticity_score = 1.0 - results['bayesian_analysis'].spoof_probability
                
                # Get or create user context
                user_context = self.user_manager.get_user(user_id)
                if not user_context:
                    user_context = self.user_manager.create_user(user_id)
                
                # Create session if needed
                user_sessions = self.user_manager.get_user_sessions(user_id)
                if not user_sessions:
                    session = self.user_manager.create_session(
                        user_id=user_id,
                        metadata={'demo_session': True, 'sample_name': sample_name}
                    )
                else:
                    session = user_sessions[0]  # Use first active session
                
                # Update session data if session exists
                if session:
                    session_data = {
                        'last_authenticity_score': authenticity_score,
                        'last_sample': sample_name,
                        'sample_count': session.session_data.get('sample_count', 0) + 1
                    }
                    self.user_manager.update_session_data(session.session_id, session_data)
            
            return results
            
        except Exception as e:
            logger.error(f"Analysis failed for {sample_name}: {e}")
            return {'error': str(e)}
    
    def _create_synthetic_audio_with_physics_features(self, 
                                                    target_delta_fr: float,
                                                    target_delta_ft: float, 
                                                    target_delta_fv: float) -> torch.Tensor:
        """Create synthetic audio designed to produce specific physics features"""
        # This is a simplified version - in practice would use more sophisticated synthesis
        duration = 3.0  # 3 seconds
        sr = 22050
        n_samples = int(duration * sr)
        
        # Create base signal with controlled characteristics
        t = torch.linspace(0, duration, n_samples)
        
        # Base frequency modulated to achieve target rotational dynamics
        base_freq = 200 + target_delta_fr * 10  # Rough mapping
        
        # Create signal with characteristics to produce target physics features
        signal = torch.sin(2 * np.pi * base_freq * t)
        
        # Add harmonic content related to translational dynamics
        signal += 0.3 * torch.sin(2 * np.pi * base_freq * 2 * t) * target_delta_ft * 100
        
        # Add noise/vibration related to vibrational dynamics
        noise = torch.randn(n_samples) * target_delta_fv * 0.1
        signal += noise
        
        # Normalize
        signal = signal / (signal.abs().max() + 1e-8)
        
        return signal
    
    def _log_analysis_results(self, scenario: Dict, results: Dict[str, Any]):
        """Log analysis results in a formatted way"""
        if 'bayesian_analysis' in results and results['bayesian_analysis']:
            ba = results['bayesian_analysis']
            
            logger.info(f"   ğŸ” Physics Features:")
            if 'physics' in results:
                physics = results['physics']
                for feat_name, feat_value in physics.items():
                    if torch.is_tensor(feat_value):
                        logger.info(f"      {feat_name}: {feat_value.item():.3f}")
            
            logger.info(f"   ğŸ§  Bayesian Analysis:")
            logger.info(f"      Spoof Probability: {ba.spoof_probability:.3f}")
            logger.info(f"      Confidence Score: {ba.confidence_score:.3f}")
            logger.info(f"      Processing Time: {ba.processing_time:.3f}s")
            
            if ba.temporal_consistency is not None:
                logger.info(f"      Temporal Consistency: {ba.temporal_consistency:.3f}")
            
            if ba.uncertainty_metrics:
                total_uncertainty = ba.uncertainty_metrics.get('total_uncertainty', 0)
                logger.info(f"      Total Uncertainty: {total_uncertainty:.3f}")
            
            if ba.causal_explanations:
                logger.info(f"      Top Causal Factors:")
                sorted_factors = sorted(ba.causal_explanations.items(), 
                                      key=lambda x: abs(x[1]) if isinstance(x[1], (int, float)) else 0, 
                                      reverse=True)[:3]
                for factor, influence in sorted_factors:
                    if isinstance(influence, (int, float)):
                        logger.info(f"        {factor}: {influence:.3f}")
            
            # Assessment
            if ba.spoof_probability > 0.7:
                assessment = "ğŸš¨ LIKELY SPOOF"
            elif ba.spoof_probability > 0.4:
                assessment = "âš ï¸ UNCERTAIN"
            else:
                assessment = "âœ… LIKELY GENUINE"
            
            logger.info(f"   ğŸ¯ Assessment: {assessment}")
            
        else:
            logger.info("   âŒ Bayesian analysis not available")
    
    def print_summary_report(self):
        """Print comprehensive summary of all tests"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š BAYESIAN NETWORKS INTEGRATION TEST SUMMARY")
        logger.info("="*60)
        
        if not self.test_results:
            logger.info("âŒ No test results available")
            return
        
        logger.info(f"âœ… Completed {len(self.test_results)} test scenarios")
        
        # Performance statistics
        processing_times = []
        accuracy_assessments = []
        
        for test_result in self.test_results:
            results = test_result['results']
            scenario = test_result['scenario']
            
            if 'bayesian_analysis' in results and results['bayesian_analysis']:
                ba = results['bayesian_analysis']
                processing_times.append(ba.processing_time)
                
                # Simple accuracy assessment
                expected = scenario['expected_authenticity']
                actual_spoof_prob = ba.spoof_probability
                
                if expected == 'high' and actual_spoof_prob < 0.3:
                    accuracy_assessments.append('correct')
                elif expected == 'low' and actual_spoof_prob > 0.6:
                    accuracy_assessments.append('correct')
                elif expected == 'uncertain':
                    accuracy_assessments.append('uncertain')
                else:
                    accuracy_assessments.append('incorrect')
        
        if processing_times:
            avg_time = sum(processing_times) / len(processing_times)
            logger.info(f"â±ï¸ Average Processing Time: {avg_time:.3f}s")
            logger.info(f"ğŸ“ˆ Processing Time Range: {min(processing_times):.3f}s - {max(processing_times):.3f}s")
        
        if accuracy_assessments:
            correct_count = accuracy_assessments.count('correct')
            total_count = len([a for a in accuracy_assessments if a != 'uncertain'])
            if total_count > 0:
                accuracy = correct_count / total_count * 100
                logger.info(f"ğŸ¯ Classification Accuracy: {accuracy:.1f}% ({correct_count}/{total_count})")
        
        # System capabilities demonstrated
        logger.info("\nğŸ”§ System Capabilities Demonstrated:")
        logger.info("   âœ… Physics-based feature extraction")
        logger.info("   âœ… Bayesian probabilistic analysis")
        logger.info("   âœ… Temporal consistency modeling")
        logger.info("   âœ… User adaptation and personalization")
        logger.info("   âœ… Uncertainty quantification")
        logger.info("   âœ… Causal inference and explanations")
        
        if self.user_manager:
            system_stats = self.user_manager.get_system_statistics()
            logger.info(f"\nğŸ‘¥ User Management Statistics:")
            logger.info(f"   Total Users: {system_stats['total_users']}")
            logger.info(f"   Active Sessions: {system_stats['active_sessions']}")
            logger.info(f"   Risk Distribution: {system_stats['risk_distribution']}")
        
        logger.info("\nğŸ‰ Bayesian Networks integration test completed successfully!")
        logger.info("="*60)

async def main():
    """Main demonstration function"""
    print("ğŸš€ Physics-Based Deepfake Detection with Bayesian Networks")
    print("   Advanced Probabilistic Analysis Demonstration")
    print("-" * 60)
    
    # Test different configuration profiles
    profiles = ["default", "real_time", "high_accuracy"]
    
    for profile in profiles:
        print(f"\nğŸ”¬ Testing with configuration profile: {profile}")
        print("-" * 40)
        
        demo = BayesianIntegrationDemo(config_profile=profile)
        
        try:
            # Initialize system
            await demo.initialize_system()
            
            # Run comprehensive tests
            await demo.test_synthetic_audio_analysis()
            await demo.test_temporal_consistency_analysis()
            await demo.test_user_adaptation()
            
            # Print summary
            demo.print_summary_report()
            
        except Exception as e:
            logger.error(f"âŒ Demo failed for profile {profile}: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "="*60 + "\n")
    
    print("ğŸ All demonstrations completed!")

if __name__ == "__main__":
    # Run the comprehensive demonstration
    asyncio.run(main()) 