#!/usr/bin/env python3
"""
Comprehensive Project Management Utility
Updated for current test_runner.py architecture with precise cleanup
"""

import os
import sys
import shutil
import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional, Any

# Add src to path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'src'))

try:
    from utils.folder_manager import initialize_project_folders, FolderManager
    FOLDER_MANAGER_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Folder manager not available: {e}")
    FOLDER_MANAGER_AVAILABLE = False


class ProjectManager:
    """
    Comprehensive project management utility for test_runner.py project
    Provides precise cleanup and reset functionality
    """
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root or current_dir)
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.cleanup_stats = {
            'files_removed': 0,
            'dirs_removed': 0,
            'bytes_freed': 0
        }
        
        # Essential directories that test_runner.py needs (DO NOT DELETE)
        self.essential_directories = [
            'src',           # Core modules
            'config',        # Configuration files
            'data',          # Input audio files (structure only)
            'venv',          # Python environment
            '.git',          # Version control
            'tests'          # Unit tests
        ]
        
        # Essential files that test_runner.py needs (DO NOT DELETE)
        self.essential_files = [
            'test_runner.py',
            'requirements.txt',
            '.gitignore',
            'README.md',
            'LICENSE'
        ]
        
        # Generated directories that can be safely reset
        self.generated_directories = [
            'cache',                    # Feature caches (regenerated automatically)
            'results',                  # CSV outputs and error logs
            'output',                   # Session reports and folder stats
            'visualizations',           # Generated plots and dashboards
            'detailed_results',         # Analysis results from save_results.py
            'logs',                     # System logs (keep structure, clear content)
            'quarantine',              # Security quarantine (keep structure, clear content)
            'checkpoints',             # Processing checkpoints (keep structure, clear content)
            'plots'                    # Generated plots (keep structure, clear content)
        ]
        
        # Generated files in root that can be safely removed
        self.generated_files = [
            'comprehensive_analysis_report.html',
            'FOLDER_INDEX.md',          # Regenerated by folder manager
            'FOLDER_CLEANUP_SUMMARY.md',
            'enhanced_visualization_*.html',
            'comprehensive_dashboard.html'
        ]
        
        # Cache patterns to clean
        self.cache_patterns = [
            'cache/*.pkl',              # Feature extraction cache
            '**/__pycache__',          # Python bytecode cache
            '**/*.pyc',                # Python compiled files
            '**/*.pyo',                # Python optimized files
            '**/.cache',               # General cache directories
        ]
        
        # External cache directories (outside project)
        self.external_cache_dirs = [
            Path.home() / '.cache' / 'voice_models',
            Path.home() / '.cache' / 'huggingface',
            Path.home() / '.cache' / 'transformers'
        ]
    
    def analyze_current_project_state(self) -> Dict[str, any]:
        """Analyze current project state and categorize all content"""
        analysis = {
            'essential_files': {'found': [], 'missing': [], 'total_size_mb': 0},
            'essential_dirs': {'found': [], 'missing': [], 'total_size_mb': 0},
            'generated_content': {'dirs': {}, 'files': [], 'total_size_mb': 0},
            'cache_content': {'internal': {}, 'external': {}, 'total_size_mb': 0},
            'unknown_content': {'files': [], 'dirs': []},
            'data_analysis': {'audio_files': 0, 'users': 0, 'test_data': False},
            'project_ready': True,
            'recommendations': []
        }
        
        # Check essential files
        for file_name in self.essential_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                size_mb = file_path.stat().st_size / (1024 * 1024)
                analysis['essential_files']['found'].append({
                    'name': file_name,
                    'size_mb': size_mb
                })
                analysis['essential_files']['total_size_mb'] += size_mb
            else:
                analysis['essential_files']['missing'].append(file_name)
                analysis['project_ready'] = False
        
        # Check essential directories
        for dir_name in self.essential_directories:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                try:
                    files = list(dir_path.rglob('*'))
                    file_count = sum(1 for f in files if f.is_file())
                    total_size = sum(f.stat().st_size for f in files if f.is_file())
                    size_mb = total_size / (1024 * 1024)
                    
                    analysis['essential_dirs']['found'].append({
                        'name': dir_name,
                        'files': file_count,
                        'size_mb': size_mb
                    })
                    analysis['essential_dirs']['total_size_mb'] += size_mb
                except (PermissionError, FileNotFoundError):
                    analysis['essential_dirs']['found'].append({
                        'name': dir_name,
                        'files': 0,
                        'size_mb': 0,
                        'error': 'Access denied'
                    })
            else:
                analysis['essential_dirs']['missing'].append(dir_name)
                if dir_name in ['src', 'config']:  # Critical directories
                    analysis['project_ready'] = False
        
        # Analyze generated content
        for dir_name in self.generated_directories:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                try:
                    files = list(dir_path.rglob('*'))
                    file_count = sum(1 for f in files if f.is_file())
                    dir_count = sum(1 for f in files if f.is_dir())
                    total_size = sum(f.stat().st_size for f in files if f.is_file())
                    size_mb = total_size / (1024 * 1024)
                    
                    analysis['generated_content']['dirs'][dir_name] = {
                        'files': file_count,
                        'dirs': dir_count,
                        'size_mb': size_mb
                    }
                    analysis['generated_content']['total_size_mb'] += size_mb
                except (PermissionError, FileNotFoundError):
                    analysis['generated_content']['dirs'][dir_name] = {
                        'files': 0, 'dirs': 0, 'size_mb': 0, 'error': 'Access denied'
                    }
        
        # Check for generated files in root
        for pattern in self.generated_files:
            if '*' in pattern:
                matching_files = list(self.project_root.glob(pattern))
                for file_path in matching_files:
                    if file_path.is_file():
                        size_mb = file_path.stat().st_size / (1024 * 1024)
                        analysis['generated_content']['files'].append({
                            'name': file_path.name,
                            'size_mb': size_mb
                        })
                        analysis['generated_content']['total_size_mb'] += size_mb
            else:
                file_path = self.project_root / pattern
                if file_path.exists():
                    size_mb = file_path.stat().st_size / (1024 * 1024)
                    analysis['generated_content']['files'].append({
                        'name': pattern,
                        'size_mb': size_mb
                    })
                    analysis['generated_content']['total_size_mb'] += size_mb
        
        # Analyze cache content
        cache_dir = self.project_root / 'cache'
        if cache_dir.exists():
            try:
                cache_files = list(cache_dir.glob('*.pkl'))
                total_size = sum(f.stat().st_size for f in cache_files)
                analysis['cache_content']['internal']['cache'] = {
                    'files': len(cache_files),
                    'size_mb': total_size / (1024 * 1024)
                }
                analysis['cache_content']['total_size_mb'] += total_size / (1024 * 1024)
            except (PermissionError, FileNotFoundError):
                pass
        
        # Check Python cache
        pycache_dirs = list(self.project_root.rglob('__pycache__'))
        if pycache_dirs:
            total_size = 0
            total_files = 0
            for pycache_dir in pycache_dirs:
                try:
                    files = list(pycache_dir.glob('*.pyc'))
                    total_files += len(files)
                    total_size += sum(f.stat().st_size for f in files)
                except:
                    continue
            
            if total_files > 0:
                analysis['cache_content']['internal']['python_cache'] = {
                    'dirs': len(pycache_dirs),
                    'files': total_files,
                    'size_mb': total_size / (1024 * 1024)
                }
                analysis['cache_content']['total_size_mb'] += total_size / (1024 * 1024)
        
        # Check external caches
        for ext_cache in self.external_cache_dirs:
            if ext_cache.exists():
                try:
                    files = list(ext_cache.rglob('*'))
                    file_count = sum(1 for f in files if f.is_file())
                    total_size = sum(f.stat().st_size for f in files if f.is_file())
                    
                    analysis['cache_content']['external'][ext_cache.name] = {
                        'path': str(ext_cache),
                        'files': file_count,
                        'size_mb': total_size / (1024 * 1024)
                    }
                    analysis['cache_content']['total_size_mb'] += total_size / (1024 * 1024)
                except:
                    pass
        
        # Analyze data directory
        data_dir = self.project_root / 'data'
        if data_dir.exists():
            try:
                users = [d for d in data_dir.iterdir() if d.is_dir()]
                audio_files = list(data_dir.rglob('*.wav')) + list(data_dir.rglob('*.mp3'))
                
                analysis['data_analysis']['users'] = len(users)
                analysis['data_analysis']['audio_files'] = len(audio_files)
                analysis['data_analysis']['test_data'] = any('test' in user.name.lower() for user in users)
            except:
                pass
        
        # Generate recommendations
        if not analysis['project_ready']:
            analysis['recommendations'].append("⚠️ Missing essential files/directories - project may not work correctly")
        
        if analysis['generated_content']['total_size_mb'] > 100:
            analysis['recommendations'].append(f"💾 Large amount of generated content ({analysis['generated_content']['total_size_mb']:.1f} MB) - consider cleanup")
        
        if analysis['cache_content']['total_size_mb'] > 50:
            analysis['recommendations'].append(f"🗂️ Significant cache usage ({analysis['cache_content']['total_size_mb']:.1f} MB) - can be safely cleared")
        
        if analysis['data_analysis']['test_data']:
            analysis['recommendations'].append("🧪 Test data detected - may be safe to remove")
        
        return analysis
    
    def display_project_analysis(self, analysis: Dict[str, any]):
        """Display comprehensive project analysis"""
        print("\n" + "="*70)
        print("PROJECT ARCHITECTURE ANALYSIS")
        print("="*70)
        
        # Project readiness
        status = "✅ READY" if analysis['project_ready'] else "⚠️ ISSUES DETECTED"
        print(f"📊 Project Status: {status}")
        
        # Essential components
        print(f"\n🔧 ESSENTIAL COMPONENTS (Required for test_runner.py):")
        print(f"├── Essential Files:")
        for file_info in analysis['essential_files']['found']:
            print(f"│   ✅ {file_info['name']} ({file_info['size_mb']:.1f} MB)")
        for missing in analysis['essential_files']['missing']:
            print(f"│   ❌ {missing} (MISSING)")
        
        print(f"├── Essential Directories:")
        for dir_info in analysis['essential_dirs']['found']:
            if 'error' in dir_info:
                print(f"│   ⚠️ {dir_info['name']}/ ({dir_info['error']})")
            else:
                print(f"│   ✅ {dir_info['name']}/ ({dir_info['files']} files, {dir_info['size_mb']:.1f} MB)")
        for missing in analysis['essential_dirs']['missing']:
            print(f"│   ❌ {missing}/ (MISSING)")
        
        total_essential = analysis['essential_files']['total_size_mb'] + analysis['essential_dirs']['total_size_mb']
        print(f"└── Total Essential Size: {total_essential:.1f} MB")
        
        # Generated content
        print(f"\n📈 GENERATED CONTENT (Safe to remove):")
        print(f"├── Generated Directories:")
        for dir_name, info in analysis['generated_content']['dirs'].items():
            if 'error' in info:
                print(f"│   📁 {dir_name}/ ({info['error']})")
            else:
                print(f"│   📁 {dir_name}/ ({info['files']} files, {info['dirs']} dirs, {info['size_mb']:.1f} MB)")
        
        if analysis['generated_content']['files']:
            print(f"├── Generated Files:")
            for file_info in analysis['generated_content']['files']:
                print(f"│   📄 {file_info['name']} ({file_info['size_mb']:.1f} MB)")
        
        print(f"└── Total Generated Size: {analysis['generated_content']['total_size_mb']:.1f} MB")
        
        # Cache analysis
        print(f"\n💾 CACHE ANALYSIS:")
        if analysis['cache_content']['internal']:
            print(f"├── Internal Caches:")
            for cache_name, info in analysis['cache_content']['internal'].items():
                if cache_name == 'cache':
                    print(f"│   🗂️ Feature Cache: {info['files']} files, {info['size_mb']:.1f} MB")
                elif cache_name == 'python_cache':
                    print(f"│   🐍 Python Cache: {info['dirs']} dirs, {info['files']} files, {info['size_mb']:.1f} MB")
        
        if analysis['cache_content']['external']:
            print(f"├── External Caches:")
            for cache_name, info in analysis['cache_content']['external'].items():
                print(f"│   🌐 {cache_name}: {info['files']} files, {info['size_mb']:.1f} MB")
        
        print(f"└── Total Cache Size: {analysis['cache_content']['total_size_mb']:.1f} MB")
        
        # Data analysis
        if analysis['data_analysis']['users'] > 0 or analysis['data_analysis']['audio_files'] > 0:
            print(f"\n🎵 DATA ANALYSIS:")
            print(f"├── Users: {analysis['data_analysis']['users']}")
            print(f"├── Audio Files: {analysis['data_analysis']['audio_files']}")
            print(f"└── Test Data: {'Yes' if analysis['data_analysis']['test_data'] else 'No'}")
        
        # Recommendations
        if analysis['recommendations']:
            print(f"\n💡 RECOMMENDATIONS:")
            for i, rec in enumerate(analysis['recommendations'], 1):
                print(f"  {i}. {rec}")
        
        # Summary
        total_size = total_essential + analysis['generated_content']['total_size_mb'] + analysis['cache_content']['total_size_mb']
        removable_size = analysis['generated_content']['total_size_mb'] + analysis['cache_content']['total_size_mb']
        
        print(f"\n📊 SUMMARY:")
        print(f"├── Total Project Size: {total_size:.1f} MB")
        print(f"├── Essential Content: {total_essential:.1f} MB")
        print(f"└── Removable Content: {removable_size:.1f} MB ({removable_size/total_size*100:.1f}%)")
    
    def perform_precise_project_reset(self, analysis: Dict[str, any], confirmed: bool = False) -> bool:
        """Perform precise project reset - only removes regenerable content"""
        if not confirmed:
            print("❌ Project reset not confirmed. Aborting.")
            return False
        
        print(f"\n🎯 PERFORMING PRECISE PROJECT RESET...")
        print(f"🔒 Essential files and directories will be preserved")
        print(f"🗑️ Only generated/cache content will be removed")
        
        reset_stats = {
            'files_removed': 0,
            'dirs_removed': 0,
            'bytes_freed': 0,
            'errors': [],
            'preserved': []
        }
        
        # 1. Clear generated directories (keep structure for some)
        print(f"\n1️⃣ Clearing generated directories...")
        structure_preserve_dirs = ['logs', 'quarantine', 'checkpoints', 'plots']
        
        for dir_name in self.generated_directories:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                try:
                    # Calculate size before removal
                    files = list(dir_path.rglob('*'))
                    file_count = sum(1 for f in files if f.is_file())
                    total_size = sum(f.stat().st_size for f in files if f.is_file())
                    
                    if dir_name in structure_preserve_dirs:
                        # Clear content but preserve structure
                        for item in dir_path.iterdir():
                            if item.is_file():
                                item.unlink()
                                reset_stats['files_removed'] += 1
                            elif item.is_dir() and item.name not in ['README.md']:
                                shutil.rmtree(item)
                                reset_stats['dirs_removed'] += 1
                        
                        # Ensure README.md exists
                        readme_path = dir_path / 'README.md'
                        if not readme_path.exists():
                            with open(readme_path, 'w') as f:
                                f.write(f"# {dir_name.title()} Directory\n\nThis directory is used by test_runner.py for {dir_name}.\n")
                        
                        print(f"    ✓ Cleared: {dir_name}/ (content removed, structure preserved)")
                        reset_stats['preserved'].append(f"{dir_name}/ structure")
                    else:
                        # Complete removal
                        shutil.rmtree(dir_path)
                        print(f"    ✓ Removed: {dir_name}/ ({file_count} files, {total_size/(1024*1024):.1f} MB)")
                        reset_stats['dirs_removed'] += 1
                    
                    reset_stats['files_removed'] += file_count
                    reset_stats['bytes_freed'] += total_size
                    
                except Exception as e:
                    error_msg = f"Failed to process {dir_name}: {e}"
                    reset_stats['errors'].append(error_msg)
                    print(f"    ❌ {error_msg}")
        
        # 2. Remove generated files in root
        print(f"\n2️⃣ Removing generated files in root...")
        for pattern in self.generated_files:
            if '*' in pattern:
                matching_files = list(self.project_root.glob(pattern))
                for file_path in matching_files:
                    if file_path.is_file():
                        try:
                            size = file_path.stat().st_size
                            file_path.unlink()
                            reset_stats['files_removed'] += 1
                            reset_stats['bytes_freed'] += size
                            print(f"    ✓ Removed: {file_path.name} ({size/1024:.1f} KB)")
                        except Exception as e:
                            error_msg = f"Failed to remove {file_path.name}: {e}"
                            reset_stats['errors'].append(error_msg)
                            print(f"    ❌ {error_msg}")
            else:
                file_path = self.project_root / pattern
                if file_path.exists():
                    try:
                        size = file_path.stat().st_size
                        file_path.unlink()
                        reset_stats['files_removed'] += 1
                        reset_stats['bytes_freed'] += size
                        print(f"    ✓ Removed: {pattern} ({size/1024:.1f} KB)")
                    except Exception as e:
                        error_msg = f"Failed to remove {pattern}: {e}"
                        reset_stats['errors'].append(error_msg)
                        print(f"    ❌ {error_msg}")
        
        # 3. Clear cache content
        print(f"\n3️⃣ Clearing cache content...")
        
        # Internal feature cache
        cache_dir = self.project_root / 'cache'
        if cache_dir.exists():
            try:
                cache_files = list(cache_dir.glob('*.pkl'))
                total_size = sum(f.stat().st_size for f in cache_files)
                
                for cache_file in cache_files:
                    cache_file.unlink()
                
                reset_stats['files_removed'] += len(cache_files)
                reset_stats['bytes_freed'] += total_size
                print(f"    ✓ Cleared feature cache: {len(cache_files)} files, {total_size/(1024*1024):.1f} MB")
            except Exception as e:
                error_msg = f"Failed to clear feature cache: {e}"
                reset_stats['errors'].append(error_msg)
                print(f"    ❌ {error_msg}")
        
        # Python cache
        pycache_dirs = list(self.project_root.rglob('__pycache__'))
        for pycache_dir in pycache_dirs:
            try:
                files = list(pycache_dir.rglob('*'))
                file_count = sum(1 for f in files if f.is_file())
                total_size = sum(f.stat().st_size for f in files if f.is_file())
                
                shutil.rmtree(pycache_dir)
                reset_stats['dirs_removed'] += 1
                reset_stats['files_removed'] += file_count
                reset_stats['bytes_freed'] += total_size
                print(f"    ✓ Removed Python cache: {pycache_dir.relative_to(self.project_root)}")
            except Exception as e:
                error_msg = f"Failed to remove Python cache {pycache_dir}: {e}"
                reset_stats['errors'].append(error_msg)
                print(f"    ❌ {error_msg}")
        
        # 4. Clean test data (optional)
        print(f"\n4️⃣ Cleaning test data...")
        data_dir = self.project_root / 'data'
        if data_dir.exists():
            test_dirs = [d for d in data_dir.iterdir() if d.is_dir() and 'test' in d.name.lower()]
            for test_dir in test_dirs:
                try:
                    files = list(test_dir.rglob('*'))
                    file_count = sum(1 for f in files if f.is_file())
                    total_size = sum(f.stat().st_size for f in files if f.is_file())
                    
                    shutil.rmtree(test_dir)
                    reset_stats['dirs_removed'] += 1
                    reset_stats['files_removed'] += file_count
                    reset_stats['bytes_freed'] += total_size
                    print(f"    ✓ Removed test data: {test_dir.name}")
                except Exception as e:
                    error_msg = f"Failed to remove test data {test_dir}: {e}"
                    reset_stats['errors'].append(error_msg)
                    print(f"    ❌ {error_msg}")
        
        # Final report
        print(f"\n🎯 PRECISE PROJECT RESET COMPLETED!")
        print(f"├── Files removed: {reset_stats['files_removed']}")
        print(f"├── Directories removed: {reset_stats['dirs_removed']}")
        print(f"├── Space freed: {reset_stats['bytes_freed'] / (1024*1024):.1f} MB")
        print(f"└── Components preserved: {len(reset_stats['preserved'])}")
        
        if reset_stats['preserved']:
            print(f"\n🔒 PRESERVED COMPONENTS:")
            for preserved in reset_stats['preserved']:
                print(f"    ✅ {preserved}")
        
        if reset_stats['errors']:
            print(f"\n⚠️ ERRORS ENCOUNTERED ({len(reset_stats['errors'])}):")
            for error in reset_stats['errors'][:5]:
                print(f"    ❌ {error}")
            if len(reset_stats['errors']) > 5:
                print(f"    ... and {len(reset_stats['errors']) - 5} more errors")
        
        # Verify essential components still exist
        print(f"\n🔍 VERIFYING ESSENTIAL COMPONENTS...")
        verification_passed = True
        
        for file_name in self.essential_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                print(f"    ✅ {file_name}")
            else:
                print(f"    ❌ {file_name} (MISSING!)")
                verification_passed = False
        
        for dir_name in self.essential_directories:
            dir_path = self.project_root / dir_name
            if dir_path.exists():
                print(f"    ✅ {dir_name}/")
            else:
                print(f"    ❌ {dir_name}/ (MISSING!)")
                verification_passed = False
        
        if verification_passed:
            print(f"\n✨ PROJECT RESET SUCCESSFUL!")
            print(f"🚀 Ready to run test_runner.py")
        else:
            print(f"\n⚠️ PROJECT RESET INCOMPLETE!")
            print(f"❌ Some essential components are missing")
        
        # Save detailed log only if needed
        log_path = self._save_reset_log(reset_stats, verification_passed)
        
        if verification_passed:
            if log_path.startswith("No log"):
                print(f"✅ Project reset completed successfully - {log_path}")
            else:
                print(f"✅ Project reset completed successfully")
                print(f"📋 Detailed log: {log_path}")
        else:
            print(f"⚠️ Project reset completed with warnings")
            print(f"📋 Review detailed log: {log_path}")
        
        return verification_passed
    
    def identify_unnecessary_files(self) -> Dict[str, List[str]]:
        """Identify files and directories that can be safely removed (legacy function)"""
        unnecessary_items = {
            'cache_files': [],
            'temp_files': [],
            'log_files': [],
            'python_cache': [],
            'empty_directories': [],
            'large_redundant_files': [],
            'backup_files': []
        }
        
        for root, dirs, files in os.walk(self.project_root):
            root_path = Path(root)
            
            # Skip virtual environment directory
            if 'venv' in root_path.parts or '.venv' in root_path.parts:
                continue
            
            # Check for Python cache directories
            if '__pycache__' in dirs:
                cache_dir = root_path / '__pycache__'
                unnecessary_items['python_cache'].append(str(cache_dir))
            
            # Check each file
            for file in files:
                file_path = root_path / file
                try:
                    file_size = file_path.stat().st_size
                    
                    # Python cache files
                    if file.endswith('.pyc') or file.endswith('.pyo'):
                        unnecessary_items['cache_files'].append(str(file_path))
                    
                    # Temporary files
                    elif file.endswith('.tmp') or file.endswith('.temp') or file.startswith('~'):
                        unnecessary_items['temp_files'].append(str(file_path))
                    
                    # Log files (keep recent ones)
                    elif file.endswith('.log') and self._is_old_log_file(file_path):
                        unnecessary_items['log_files'].append(str(file_path))
                    
                    # Backup files
                    elif file.endswith('.bak') or file.endswith('.backup') or file.endswith('~'):
                        unnecessary_items['backup_files'].append(str(file_path))
                    
                    # Large cache pickle files (keep recent ones)
                    elif file.endswith('.pkl') and 'cache' in str(root_path).lower():
                        if file_size > 500 * 1024 and self._is_old_cache_file(file_path):
                            unnecessary_items['large_redundant_files'].append(str(file_path))
                
                except (PermissionError, FileNotFoundError):
                    continue
        
        return unnecessary_items
    
    def _is_old_log_file(self, file_path: Path) -> bool:
        """Check if log file is older than 7 days"""
        try:
            file_age = time.time() - file_path.stat().st_mtime
            return file_age > 7 * 24 * 3600  # 7 days
        except:
            return False
    
    def _is_old_cache_file(self, file_path: Path) -> bool:
        """Check if cache file is older than 1 day"""
        try:
            file_age = time.time() - file_path.stat().st_mtime
            return file_age > 24 * 3600  # 1 day
        except:
            return False
    
    def display_cleanup_report(self, unnecessary_items: Dict[str, List[str]]):
        """Display detailed cleanup report (legacy function)"""
        total_files = sum(len(items) for items in unnecessary_items.values())
        total_size = self.calculate_space_savings(unnecessary_items)
        
        print(f"\n📊 Summary:")
        print(f"  Total unnecessary items: {total_files}")
        print(f"  Potential space savings: {total_size / (1024*1024):.1f} MB")
        
        return total_files, total_size
    
    def calculate_space_savings(self, unnecessary_items: Dict[str, List[str]]) -> int:
        """Calculate total space that would be freed"""
        total_size = 0
        
        for category, items in unnecessary_items.items():
            for item_path in items:
                try:
                    path = Path(item_path)
                    if path.is_file():
                        total_size += path.stat().st_size
                    elif path.is_dir():
                        total_size += sum(f.stat().st_size for f in path.rglob('*') if f.is_file())
                except:
                    continue
        
        return total_size
    
    def perform_cleanup(self, unnecessary_items: Dict[str, List[str]], categories_to_clean: List[str] = None):
        """Perform the actual cleanup (legacy function)"""
        if categories_to_clean is None:
            categories_to_clean = ['python_cache', 'temp_files', 'log_files']
        
        # Reset cleanup stats for this operation
        self.cleanup_stats = {
            'files_removed': 0,
            'dirs_removed': 0,
            'bytes_freed': 0
        }
        
        print(f"\n🧹 Starting cleanup of categories: {categories_to_clean}")
        
        # Validate that categories exist in unnecessary_items
        valid_categories = []
        for category in categories_to_clean:
            if category in unnecessary_items and unnecessary_items[category]:
                valid_categories.append(category)
                print(f"  ✓ {category}: {len(unnecessary_items[category])} items")
            else:
                print(f"  ⚠️  {category}: No items found or category doesn't exist")
        
        if not valid_categories:
            print("❌ No valid categories with items to clean!")
            return
        
        # Actually perform cleanup
        for category in valid_categories:
            items = unnecessary_items[category]
            print(f"\n  🗑️  Cleaning {category.replace('_', ' ')}...")
            
            for item_path in items:
                try:
                    path = Path(item_path)
                    
                    if not path.exists():
                        continue
                    
                    if path.is_file():
                        size = path.stat().st_size
                        path.unlink()
                        self.cleanup_stats['files_removed'] += 1
                        self.cleanup_stats['bytes_freed'] += size
                        print(f"    ✓ Removed file: {path.name}")
                    
                    elif path.is_dir():
                        try:
                            size = sum(f.stat().st_size for f in path.rglob('*') if f.is_file())
                            file_count = sum(1 for f in path.rglob('*') if f.is_file())
                        except:
                            size = 0
                            file_count = 0
                        
                        shutil.rmtree(path)
                        self.cleanup_stats['dirs_removed'] += 1
                        self.cleanup_stats['bytes_freed'] += size
                        print(f"    ✓ Removed directory: {path.name}")
                
                except Exception as e:
                    print(f"    ❌ Failed to remove {item_path}: {e}")
        
        print(f"\n✅ Cleanup completed!")
        print(f"  📁 Files removed: {self.cleanup_stats['files_removed']}")
        print(f"  📂 Directories removed: {self.cleanup_stats['dirs_removed']}")
        print(f"  💾 Space freed: {self.cleanup_stats['bytes_freed'] / (1024*1024):.2f} MB")
        
        return self.cleanup_stats
    
    def show_folder_structure(self):
        """Display the current folder structure (legacy function)"""
        print("\n📁 CURRENT PROJECT STRUCTURE:")
        print("=" * 30)
        
        # List main directories
        for item in sorted(self.project_root.iterdir()):
            if item.is_dir() and not item.name.startswith('.') and item.name != '__pycache__':
                print(f"📁 {item.name}/")
                
                try:
                    files = [f for f in item.iterdir() if f.is_file() and not f.name.startswith('.')]
                    if files:
                        for file in sorted(files)[:3]:
                            size_kb = file.stat().st_size / 1024
                            print(f"   📄 {file.name} ({size_kb:.1f} KB)")
                        if len(files) > 3:
                            print(f"   ... and {len(files) - 3} more files")
                
                except (PermissionError, Exception):
                    print("   (Error reading directory)")
        
        # Show key files in root
        print(f"\n📄 Key files in root:")
        key_files = ['test_runner.py', 'requirements.txt', 'README.md']
        for filename in key_files:
            filepath = self.project_root / filename
            if filepath.exists():
                size_kb = filepath.stat().st_size / 1024
                print(f"   📄 {filename} ({size_kb:.1f} KB)")
    
    def test_folder_management(self) -> bool:
        """Test the comprehensive folder management system (legacy function)"""
        
        print("🗂️  FOLDER MANAGEMENT SYSTEM TEST")
        print("=" * 50)
        
        if not FOLDER_MANAGER_AVAILABLE:
            print("❌ Folder management module not available")
            return False
        
        try:
            manager = FolderManager(str(self.project_root))
            print(f"   ✅ Manager created with session ID: {manager.session_id}")
            
            setup_stats = manager.setup_all_folders()
            print(f"   ✅ Setup completed successfully!")
            print(f"      📁 Folders created: {setup_stats['folders_created']}")
            
            return True
        except Exception as e:
            print(f"   ❌ Failed: {e}")
            return False

    def _save_reset_log(self, stats: Dict[str, Any], verification_passed: bool) -> str:
        """Save detailed reset log only when there are issues or when explicitly requested"""
        
        # Only create log if there were issues, errors, or significant actions taken
        needs_log = (
            stats['files_removed'] > 0 or \
            stats['dirs_removed'] > 0 or \
            len(stats['errors']) > 0 or\
            not verification_passed or\
            stats['bytes_freed'] > 1024 * 1024  # Log if > 1MB freed
        )
        
        if not needs_log:
            return "No log created - operation was clean with minimal changes"
        
        log_file = self.project_root / f'precise_reset_log_{self.session_id}.json'
        
        log_data = {
            'reset_timestamp': datetime.now().isoformat(),
            'session_id': self.session_id,
            'type': 'precise_reset',
            'stats': stats,
            'verification_passed': verification_passed,
            'analysis_used': self._get_project_analysis()
        }
        
        with open(log_file, 'w') as f:
            json.dump(log_data, f, indent=2)
        
        return str(log_file)

    def _get_project_analysis(self) -> Dict[str, Any]:
        """Get current project analysis for logging purposes"""
        try:
            return self.analyze_current_project_state()
        except Exception as e:
            return {
                'error': f'Could not analyze project state: {e}',
                'timestamp': datetime.now().isoformat()
            }


def main():
    """Main execution function with streamlined menu for essential operations"""
    print("🛠️ PHYSICS FEATURES PROJECT MANAGER")
    print("=" * 70)
    print("Streamlined for essential test_runner.py project management")
    
    # Initialize project manager
    manager = ProjectManager()
    
    while True:
        print(f"\n📋 STREAMLINED PROJECT MANAGER MENU:")
        print(f"  1. 📊 Analyze Project Architecture & Status")
        print(f"  2. 🧹 Perform Safe Cleanup (Cache & Temp Files)")
        print(f"  3. 🎯 PRECISE PROJECT RESET (Ready for test_runner.py)")
        print(f"  4. 🚪 Exit")
        
        try:
            choice = input("\nEnter your choice (1-4): ").strip()
        except KeyboardInterrupt:
            print("\nOperation cancelled by user.")
            break
        
        if choice == '1':
            # Comprehensive project analysis with enhanced reporting
            print(f"\n{'='*70}")
            print("📊 COMPREHENSIVE PROJECT ANALYSIS")
            print(f"{'='*70}")
            
            try:
                analysis = manager.analyze_current_project_state()
                manager.display_project_analysis(analysis)
                
                # Additional recommendations
                print(f"\n🔍 DETAILED RECOMMENDATIONS:")
                if analysis['project_ready']:
                    print(f"  ✅ Project is fully ready for test_runner.py execution")
                    print(f"  💡 All essential components are present and accessible")
                    
                    if analysis['cache_content']['total_size_mb'] > 10:
                        print(f"  💾 Consider cleanup: {analysis['cache_content']['total_size_mb']:.1f} MB of cache can be cleared")
                    
                    if analysis['generated_content']['total_size_mb'] > 50:
                        print(f"  🗂️ Consider reset: {analysis['generated_content']['total_size_mb']:.1f} MB of generated content can be removed")
                else:
                    print(f"  ⚠️ Project has missing components that may affect functionality")
                    print(f"  🔧 Consider checking essential files and directories")
                
                # Show quick stats
                total_size = (analysis['essential_files']['total_size_mb'] + 
                            analysis['essential_dirs']['total_size_mb'] + 
                            analysis['generated_content']['total_size_mb'] + 
                            analysis['cache_content']['total_size_mb'])
                
                print(f"\n📈 QUICK STATISTICS:")
                print(f"  📁 Total Project Size: {total_size:.1f} MB")
                print(f"  🔧 Essential Content: {analysis['essential_files']['total_size_mb'] + analysis['essential_dirs']['total_size_mb']:.1f} MB")
                print(f"  📊 Generated Content: {analysis['generated_content']['total_size_mb']:.1f} MB")
                print(f"  💾 Cache Content: {analysis['cache_content']['total_size_mb']:.1f} MB")
                
            except Exception as e:
                print(f"❌ Error during analysis: {e}")
                print(f"💡 Try running with administrator privileges if permission errors occur")
        
        elif choice == '2':
            # Enhanced safe cleanup with better identification
            print(f"\n{'='*70}")
            print("🧹 ENHANCED SAFE CLEANUP")
            print(f"{'='*70}")
            
            try:
                print("🔍 Scanning for unnecessary files...")
                
                # Custom safe cleanup logic
                cleanup_stats = {
                    'python_cache': {'files': 0, 'dirs': 0, 'size_mb': 0},
                    'temp_files': {'files': 0, 'size_mb': 0},
                    'old_logs': {'files': 0, 'size_mb': 0},
                    'feature_cache': {'files': 0, 'size_mb': 0}
                }
                
                # Find Python cache
                pycache_dirs = list(manager.project_root.rglob('__pycache__'))
                if pycache_dirs:
                    total_size = 0
                    total_files = 0
                    for pycache_dir in pycache_dirs:
                        try:
                            files = list(pycache_dir.glob('*.pyc'))
                            total_files += len(files)
                            total_size += sum(f.stat().st_size for f in files)
                        except:
                            continue
                    
                    cleanup_stats['python_cache'] = {
                        'files': total_files,
                        'dirs': len(pycache_dirs),
                        'size_mb': total_size / (1024 * 1024)
                    }
                
                # Find temporary files
                temp_patterns = ['**/*.tmp', '**/*.temp', '**/~*']
                temp_files = []
                for pattern in temp_patterns:
                    temp_files.extend(manager.project_root.glob(pattern))
                
                if temp_files:
                    total_size = sum(f.stat().st_size for f in temp_files if f.is_file())
                    cleanup_stats['temp_files'] = {
                        'files': len(temp_files),
                        'size_mb': total_size / (1024 * 1024)
                    }
                
                # Find old cache files
                cache_dir = manager.project_root / 'cache'
                if cache_dir.exists():
                    try:
                        cache_files = list(cache_dir.glob('*.pkl'))
                        old_cache = []
                        for cache_file in cache_files:
                            try:
                                file_age = time.time() - cache_file.stat().st_mtime
                                if file_age > 24 * 3600:  # Older than 1 day
                                    old_cache.append(cache_file)
                            except:
                                continue
                        
                        if old_cache:
                            total_size = sum(f.stat().st_size for f in old_cache)
                            cleanup_stats['feature_cache'] = {
                                'files': len(old_cache),
                                'size_mb': total_size / (1024 * 1024)
                            }
                    except:
                        pass
                
                # Display findings
                total_cleanable_mb = sum(cat['size_mb'] for cat in cleanup_stats.values())
                total_cleanable_files = sum(cat.get('files', 0) for cat in cleanup_stats.values())
                
                if total_cleanable_files == 0:
                    print("✨ Project is already clean! No unnecessary files found.")
                    continue
                
                print(f"\n📋 CLEANUP ANALYSIS:")
                for category, stats in cleanup_stats.items():
                    if stats.get('files', 0) > 0:
                        cat_name = category.replace('_', ' ').title()
                        if 'dirs' in stats:
                            print(f"  📁 {cat_name}: {stats['dirs']} dirs, {stats['files']} files ({stats['size_mb']:.1f} MB)")
                        else:
                            print(f"  📄 {cat_name}: {stats['files']} files ({stats['size_mb']:.1f} MB)")
                
                print(f"\n📊 CLEANUP SUMMARY:")
                print(f"  🗑️ Total items to clean: {total_cleanable_files}")
                print(f"  💾 Total space to free: {total_cleanable_mb:.1f} MB")
                
                confirm = input(f"\n❓ Proceed with safe cleanup? (y/n): ").lower().strip()
                
                if confirm in ['y', 'yes']:
                    print(f"\n🧹 Performing safe cleanup...")
                    
                    removed_files = 0
                    removed_dirs = 0
                    freed_bytes = 0
                    
                    # Clean Python cache
                    for pycache_dir in pycache_dirs:
                        try:
                            files = list(pycache_dir.rglob('*'))
                            file_count = sum(1 for f in files if f.is_file())
                            total_size = sum(f.stat().st_size for f in files if f.is_file())
                            
                            shutil.rmtree(pycache_dir)
                            removed_dirs += 1
                            removed_files += file_count
                            freed_bytes += total_size
                            print(f"    ✓ Removed: {pycache_dir.relative_to(manager.project_root)}")
                        except Exception as e:
                            print(f"    ❌ Failed to remove {pycache_dir}: {e}")
                    
                    # Clean temporary files
                    for temp_file in temp_files:
                        try:
                            if temp_file.is_file():
                                size = temp_file.stat().st_size
                                temp_file.unlink()
                                removed_files += 1
                                freed_bytes += size
                                print(f"    ✓ Removed: {temp_file.name}")
                        except Exception as e:
                            print(f"    ❌ Failed to remove {temp_file}: {e}")
                    
                    # Clean old cache
                    if cache_dir.exists():
                        old_cache_files = []
                        for cache_file in cache_dir.glob('*.pkl'):
                            try:
                                file_age = time.time() - cache_file.stat().st_mtime
                                if file_age > 24 * 3600:
                                    old_cache_files.append(cache_file)
                            except:
                                continue
                        
                        for cache_file in old_cache_files:
                            try:
                                size = cache_file.stat().st_size
                                cache_file.unlink()
                                removed_files += 1
                                freed_bytes += size
                                print(f"    ✓ Removed old cache: {cache_file.name}")
                            except Exception as e:
                                print(f"    ❌ Failed to remove {cache_file}: {e}")
                    
                    print(f"\n✅ CLEANUP COMPLETED!")
                    print(f"  📁 Files removed: {removed_files}")
                    print(f"  📂 Directories removed: {removed_dirs}")
                    print(f"  💾 Space freed: {freed_bytes / (1024*1024):.2f} MB")
                    
                else:
                    print("🚫 Safe cleanup cancelled.")
                    
            except Exception as e:
                print(f"❌ Error during cleanup: {e}")
        
        elif choice == '3':
            # Enhanced precise project reset
            print(f"\n{'='*70}")
            print("🎯 PRECISE PROJECT RESET")
            print(f"{'='*70}")
            
            try:
                analysis = manager.analyze_current_project_state()
                
                print(f"📊 RESET PREVIEW:")
                removable_size = analysis['generated_content']['total_size_mb'] + analysis['cache_content']['total_size_mb']
                essential_size = analysis['essential_files']['total_size_mb'] + analysis['essential_dirs']['total_size_mb']
                
                print(f"├── Essential Content (preserved): {essential_size:.1f} MB")
                print(f"├── Removable Content (will be deleted): {removable_size:.1f} MB")
                print(f"└── Project readiness after reset: ✅ Ready for test_runner.py")
                
                print(f"\n🎯 RESET OPERATION DETAILS:")
                print(f"✅ WILL PRESERVE:")
                print(f"  • Essential files: test_runner.py, requirements.txt, etc.")
                print(f"  • Core directories: src/, config/, data/ (structure)")
                print(f"  • Your audio data and user configurations")
                print(f"  • Git repository and version control")
                
                print(f"\n🗑️ WILL REMOVE:")
                print(f"  • All generated content: results/, visualizations/, output/")
                print(f"  • All cache files: feature cache, Python cache")
                print(f"  • All temporary and log files")
                print(f"  • All analysis reports and plots")
                
                if removable_size < 1:
                    print(f"\n💡 Project is already clean! Reset may not be necessary.")
                    print(f"   Only {removable_size:.2f} MB would be removed.")
                
                print(f"\n⚠️ CONFIRMATION REQUIRED:")
                print(f"This will remove {removable_size:.1f} MB of generated content.")
                confirm = input("Type 'RESET' to confirm precise project reset: ").strip()
                
                if confirm == 'RESET':
                    print(f"\n⏳ Performing precise project reset...")
                    success = manager.perform_precise_project_reset(analysis, confirmed=True)
                    
                    if success:
                        print(f"\n🎉 PRECISE RESET COMPLETED SUCCESSFULLY!")
                        print(f"🚀 Project is now ready for fresh test_runner.py execution")
                        print(f"💡 All essential components verified and preserved")
                    else:
                        print(f"\n⚠️ Reset completed but verification failed")
                        print(f"🔧 Some essential components may be missing")
                else:
                    print(f"\n✅ Precise reset cancelled - project unchanged")
                    
            except Exception as e:
                print(f"❌ Error during reset: {e}")
        
        elif choice == '4':
            print("\n👋 Exiting Project Manager")
            print("🚀 Project is ready for test_runner.py execution!")
            break
        
        else:
            print("\n❌ Invalid choice. Please enter 1-4.")


if __name__ == "__main__":
    main() 